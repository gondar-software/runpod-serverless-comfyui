{
    "3": {
      "inputs": {
        "seed": 152957103463352,
        "steps": 8,
        "cfg": 1,
        "sampler_name": "euler",
        "scheduler": "normal",
        "denoise": 1,
        "model": [
          "84",
          0
        ],
        "positive": [
          "99",
          0
        ],
        "negative": [
          "99",
          1
        ],
        "latent_image": [
          "99",
          2
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "7": {
      "inputs": {
        "text": "",
        "clip": [
          "115",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Negative Prompt)"
      }
    },
    "8": {
      "inputs": {
        "samples": [
          "3",
          0
        ],
        "vae": [
          "32",
          0
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "9": {
      "inputs": {
        "filename_prefix": "ComfyUI",
        "images": [
          "8",
          0
        ]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    },
    "26": {
      "inputs": {
        "guidance": 10,
        "conditioning": [
          "96",
          0
        ]
      },
      "class_type": "FluxGuidance",
      "_meta": {
        "title": "FluxGuidance"
      }
    },
    "31": {
      "inputs": {
        "unet_name": "flux1-dev-fp8.safetensors",
        "weight_dtype": "fp8_e4m3fn"
      },
      "class_type": "UNETLoader",
      "_meta": {
        "title": "Load Diffusion Model"
      }
    },
    "32": {
      "inputs": {
        "vae_name": "ae.safetensors"
      },
      "class_type": "VAELoader",
      "_meta": {
        "title": "Load VAE"
      }
    },
    "34": {
      "inputs": {
        "clip_name1": "clip_l.safetensors",
        "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
        "type": "flux",
        "device": "default"
      },
      "class_type": "DualCLIPLoader",
      "_meta": {
        "title": "DualCLIPLoader"
      }
    },
    "48": {
      "inputs": {
        "text": "In cute good looking Pixar 3d Styles , high definition , attractive characters , vibrant"
      },
      "class_type": "Text Multiline",
      "_meta": {
        "title": "trigger word"
      }
    },
    "83": {
      "inputs": {
        "width": 1024,
        "height": 1024,
        "interpolation": "lanczos",
        "method": "keep proportion",
        "condition": "always",
        "multiple_of": 0,
        "image": [
          "130",
          0
        ]
      },
      "class_type": "ImageResize+",
      "_meta": {
        "title": "ðŸ”§ Image Resize"
      }
    },
    "84": {
      "inputs": {
        "weight": 1,
        "start_at": 0,
        "end_at": 1,
        "model": [
          "98",
          0
        ],
        "pulid_flux": [
          "85",
          0
        ],
        "eva_clip": [
          "86",
          0
        ],
        "face_analysis": [
          "87",
          0
        ],
        "image": [
          "127",
          0
        ]
      },
      "class_type": "ApplyPulidFlux",
      "_meta": {
        "title": "Apply PuLID Flux"
      }
    },
    "85": {
      "inputs": {
        "pulid_file": "pulid_flux_v0.9.1.safetensors"
      },
      "class_type": "PulidFluxModelLoader",
      "_meta": {
        "title": "Load PuLID Flux Model"
      }
    },
    "86": {
      "inputs": {},
      "class_type": "PulidFluxEvaClipLoader",
      "_meta": {
        "title": "Load Eva Clip (PuLID Flux)"
      }
    },
    "87": {
      "inputs": {
        "provider": "CUDA"
      },
      "class_type": "PulidFluxInsightFaceLoader",
      "_meta": {
        "title": "Load InsightFace (PuLID Flux)"
      }
    },
    "91": {
      "inputs": {
        "style_model_name": "flux1-redux-dev.safetensors"
      },
      "class_type": "StyleModelLoader",
      "_meta": {
        "title": "Load Style Model"
      }
    },
    "92": {
      "inputs": {
        "crop": "center",
        "clip_vision": [
          "95",
          0
        ],
        "image": [
          "127",
          0
        ]
      },
      "class_type": "CLIPVisionEncode",
      "_meta": {
        "title": "CLIP Vision Encode"
      }
    },
    "94": {
      "inputs": {
        "image_strength": "high",
        "conditioning": [
          "26",
          0
        ],
        "style_model": [
          "91",
          0
        ],
        "clip_vision_output": [
          "92",
          0
        ]
      },
      "class_type": "StyleModelApplySimple",
      "_meta": {
        "title": "StyleModelApplySimple"
      }
    },
    "95": {
      "inputs": {
        "clip_name": "sigclip_vision_patch14_384.safetensors"
      },
      "class_type": "CLIPVisionLoader",
      "_meta": {
        "title": "Load CLIP Vision"
      }
    },
    "96": {
      "inputs": {
        "text": [
          "104",
          0
        ],
        "clip": [
          "115",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Prompt)"
      }
    },
    "98": {
      "inputs": {
        "lora_name": "flux1-depth-dev-lora.safetensors",
        "strength_model": 1,
        "model": [
          "115",
          0
        ]
      },
      "class_type": "LoraLoaderModelOnly",
      "_meta": {
        "title": "LoraLoaderModelOnly"
      }
    },
    "99": {
      "inputs": {
        "positive": [
          "94",
          0
        ],
        "negative": [
          "7",
          0
        ],
        "vae": [
          "32",
          0
        ],
        "pixels": [
          "83",
          0
        ]
      },
      "class_type": "InstructPixToPixConditioning",
      "_meta": {
        "title": "InstructPixToPixConditioning"
      }
    },
    "102": {
      "inputs": {
        "task": "more detailed caption",
        "text_input": "",
        "max_new_tokens": 1024,
        "num_beams": 3,
        "do_sample": false,
        "fill_mask": false,
        "florence2_model": [
          "103",
          0
        ],
        "image": [
          "127",
          0
        ]
      },
      "class_type": "LayerUtility: Florence2Image2Prompt",
      "_meta": {
        "title": "LayerUtility: Florence2 Image2Prompt(Advance)"
      }
    },
    "103": {
      "inputs": {
        "version": "large-PromptGen-v1.5"
      },
      "class_type": "LayerMask: LoadFlorence2Model",
      "_meta": {
        "title": "LayerMask: Load Florence2 Model(Advance)"
      }
    },
    "104": {
      "inputs": {
        "string1": [
          "48",
          0
        ],
        "string2": [
          "102",
          0
        ],
        "delimiter": ","
      },
      "class_type": "JoinStrings",
      "_meta": {
        "title": "Join Strings"
      }
    },
    "115": {
      "inputs": {
        "lora_name": "Hyper-FLUX.1-dev-8steps-lora.safetensors",
        "strength_model": 0.1,
        "strength_clip": 0.1,
        "model": [
          "128",
          0
        ],
        "clip": [
          "128",
          1
        ]
      },
      "class_type": "LoraLoader",
      "_meta": {
        "title": "Load LoRA"
      }
    },
    "127": {
      "inputs": {
        "width": 1024,
        "height": 1024,
        "interpolation": "nearest",
        "method": "keep proportion",
        "condition": "always",
        "multiple_of": 0,
        "image": [
          "111",
          0
        ]
      },
      "class_type": "ImageResize+",
      "_meta": {
        "title": "ðŸ”§ Image Resize"
      }
    },
    "128": {
      "inputs": {
        "strength_model": 1,
        "strength_clip": 1,
        "civitai_model_id": "733001",
        "model": [
          "31",
          0
        ],
        "clip": [
          "34",
          0
        ]
      },
      "class_type": "LoadLoraFromCivitAI",
      "_meta": {
        "title": "Load Lora From CivitAI"
      }
    },
    "111": {
      "inputs": {
        "url_or_path": "https://i.ibb.co/k2D6q5mB/Whats-App-Image-2025-03-31-at-11-06-24-PM.jpg"
      },
      "class_type": "LoadImageFromUrlOrPath",
      "_meta": {
        "title": "LoadImageFromUrlOrPath"
      }
    },
    "130": {
      "inputs": {
        "ckpt_name": "depth_anything_vitl14.pth",
        "resolution": 512,
        "image": [
          "111",
          0
        ]
      },
      "class_type": "DepthAnythingPreprocessor",
      "_meta": {
        "title": "Depth Anything"
      }
    }
  }